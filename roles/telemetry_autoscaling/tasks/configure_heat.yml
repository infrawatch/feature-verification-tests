---
# RE: alarm definitions, it might be cleaner to add two of each alarm, and block off the entire resource, one for gnocchi and one for prom.
# instead of having if/else blocks inside the resource.
#
# TODO(efoley) Consider a heat stack to create the pre-reqs for the autoscaling example.
# i.e. create the sec group, network, etc
# TODO(efoley): Move the HOT templates into templates/ dir for the role
- name: Create the generic archive policy for autoscaling
  when: metrics_backend == "gnocchi"
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} metric archive-policy create generic \
    --back-window 0 \
    --definition timespan:'4:00:00',granularity:'0:01:00',points:240 \
    --aggregation-method 'rate:mean' \
    --aggregation-method 'mean';
  register: result
  failed_when: result.rc >= 1

- name: RHOSO-12656 Verify that the archive policy was created
  when: metrics_backend == "gnocchi"
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} metric archive-policy show generic;
  register: result
  failed_when: result.rc >= 1

- name: Create "vnf" directory under templates
  ansible.builtin.shell: |
    mkdir -p $HOME/templates/autoscaling/vnf/

  # TODO: Pass the parameters correctly. When I tried to pass the parameters
  # into the template.yaml file, they weren't passed to the instance initially.
- name: RHOSO-12657 Configure heat template for automatically scaling instances
  ansible.builtin.copy:
    dest: ~/templates/autoscaling/vnf/instance.yaml
    content: |
      heat_template_version: wallaby
      description: Template to control scaling of VNF instance

      parameters:
        metadata:
          type: json
        image:
          type: string
          description: image used to create instance
          default: {{ stack_image | default("workload_image_1") }}
        flavor:
          type: string
          description: instance flavor to be used
          default: {{ stack_flavor | default("workload_flavor_1") }}
        key_name:
          type: string
          description: keypair to be used
          default: workload_key_1
        network:
          type: string
          description: project network to attach instance to
          default: {{ stack_network | default("workload_internal_net_1") }}
        external_network:
          type: string
          description: network used for floating IPs
          default: {{ stack_external_network | default("public") }}
        server_name_prefix:
          type: string
          description: a prefix for each server name.
          default: ""
        security_group:
          type: string
          description: the security group for the instances
          default: basic

      resources:
        vnf:
          type: OS::Nova::Server
          properties:
            {% if metrics_backend == "prometheus" -%}
            name:
              list_join: ["", [{get_param: server_name_prefix}, {get_param: OS::stack_name}]]
            {% endif -%}
            flavor: {get_param: flavor}
            #key_name: {get_param: key_name}
            image: { get_param: image }
            metadata: { get_param: metadata }
            networks:
              - port: { get_resource: port }

        port:
          type: OS::Neutron::Port
          properties:
            network: {get_param: network}
            security_groups:
              - { get_param: security_group }

        floating_ip:
          type: OS::Neutron::FloatingIP
          properties:
            floating_network: {get_param: external_network }

        floating_ip_assoc:
          type: OS::Neutron::FloatingIPAssociation
          properties:
            floatingip_id: { get_resource: floating_ip }
            port_id: { get_resource: port }

- name: RHOSO-12658 Create the resource to reference in the heat template
  ansible.builtin.copy:
    dest: ~/templates/autoscaling/vnf/resources.yaml
    content: |
      resource_registry:
        "OS::Nova::Server::VNF": ./instance.yaml
     # parameters:
     #   image: cirros
     #   flavor: m1.small
     #   network: private
     #   security_group: basic

- name: RHOSO-12659 Create the deployment template for heat to control instance scaling
  ansible.builtin.copy:
    dest: ~/templates/autoscaling/vnf/template.yaml
    content: |
      heat_template_version: wallaby
      description:  Example auto scale group, policy and alarm
      parameters:
        server_name_prefix:
          description: A prefix for servers created by this stack. Can be used in queries.
          type: string
          default: autoscaling_server_
            #image:
            #  type: string
            #  description: image used to create instance
            #  default: "{{ stack_network| default( 'workload_image_1') }}"
            #flavor:
            #  type: string
            #  description: instance flavor to be used
            #  default: "{{ stack_flavor | default('workload_flavor_1') }}"
            #key_name:
            #  type: string
            #  description: keypair to be used
            #  default: workload_key_1
            #network:
            #  type: string
            #  description: project network to attach instance to
            #  default: "{{ stack_network | default('workload_internal_net_1') }}"
            #external_network:
            #  type: string
            #  description: network used for floating IPs
            #  default: public

      resources:
        scaleup_group:
          type: OS::Heat::AutoScalingGroup
          properties:
            max_size: 3
            min_size: 1
            desired_capacity: 1
            resource:
              type: OS::Nova::Server::VNF
              # resource definieiton for the resource to be created by the group.
              #  this passes in parameters to the resource.
              #  So I can put a name_prefix here and it'll be set as the name...
              #  But the parameter is needed in the VNF.
              #  Can I set the name in an OS::Nova::Server?
              # This sets the property/metadata for the VNF
              #  name should be set here, but maybe not as metadata
              # network: { get_param: network }
              # flavor: { get_param: flavor }
              # image: { get_param: image }
              properties:
                server_name_prefix: { get_param: server_name_prefix }
                metadata: {"metering.server_group": {get_param: "OS::stack_id"}}


        scaleup_policy:
          type: OS::Heat::ScalingPolicy
          properties:
            adjustment_type: change_in_capacity
            auto_scaling_group_id: { get_resource: scaleup_group }
            cooldown: 60
            scaling_adjustment: 1

        scaledown_policy:
          type: OS::Heat::ScalingPolicy
          properties:
            adjustment_type: change_in_capacity
            auto_scaling_group_id: { get_resource: scaleup_group }
            cooldown: 60
            scaling_adjustment: -1

        cpu_alarm_high:
          {% if metrics_backend == "gnocchi" -%}
          type: OS::Aodh::GnocchiAggregationByResourcesAlarm
          {% endif -%}
          {% if metrics_backend == "prometheus" -%}
          type: OS::Aodh::PrometheusAlarm
          {% endif -%}
          properties:
            description: Scale up instance if CPU > 50%
            {% if metrics_backend == "gnocchi" -%}
            metric: cpu
            aggregation_method: rate:mean
            granularity: 300
            evaluation_periods: 1
            resource_type: instance
            threshold: 30000000000.0
            {% endif -%}
            {% if metrics_backend == "prometheus" -%}
            threshold: 50
            {% endif -%}
            comparison_operator: gt
            alarm_actions:
              - str_replace:
                  template: trust+url
                  params:
                    url: {get_attr: [scaleup_policy, signal_url]}
            query:
              {% if metrics_backend == "gnocchi" -%}
              list_join:
                - ''
                - - {'=': {server_group: {get_param: "OS::stack_id"}}}
              {% endif -%}
              {% if metrics_backend == "prometheus" -%}
              str_replace:
                template: "(rate(ceilometer_cpu{resource_name=~'server_name_prefix.*'}[150s]))/10000000"
                params:
                  server_name_prefix: {get_param: server_name_prefix}
              {%- endif %}

        cpu_alarm_low:
          {% if metrics_backend == "gnocchi" -%}
          type: OS::Aodh::GnocchiAggregationByResourcesAlarm
          {% endif -%}
          {% if metrics_backend == "prometheus" -%}
          type: OS::Aodh::PrometheusAlarm
          {% endif -%}
          properties:
            description: Scale down instance if CPU < 20%
            {% if metrics_backend == "gnocchi" -%}
            metric: cpu
            aggregation_method: rate:mean
            granularity: 300
            evaluation_periods: 1
            resource_type: instance
            threshold: 12000000000.0
            {% endif -%}
            threshold: 20
            comparison_operator: lt
            alarm_actions:
              - str_replace:
                  template: trust+url
                  params:
                    url: {get_attr: [scaledown_policy, signal_url]}
            query:
              {% if metrics_backend == "gnocchi" -%}
              list_join:
                - ''
                - - {'=': {server_group: {get_param: "OS::stack_id"}}}
              {% endif -%}
              {% if metrics_backend == "prometheus" -%}
              str_replace:
                template: "(rate(ceilometer_cpu{resource_name=~'server_name_prefix.*'}[150s]))/10000000"
                params:
                  server_name_prefix: {get_param: server_name_prefix}
              {% endif %}

      outputs:
        scaleup_policy_signal_url:
          value: {get_attr: [scaleup_policy, alarm_url]}

        scaledown_policy_signal_url:
          value: {get_attr: [scaledown_policy, alarm_url]}
