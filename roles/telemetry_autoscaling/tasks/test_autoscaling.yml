---
  # NOTE: The format of the output appears to have changed; There are now 2
  # IP addresses, and the second one is the one associated with the floating IP
- name: Register instance IP
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    export STACK_ID=$({{ openstack_cmd }} stack show {{ stack_name }} -c id -f value)
    {{ openstack_cmd }} server list --long -c Networks -c 'Properties' | \
        grep -i $STACK_ID | \
        awk -F'=' '{print $2}' | \
        awk -F'|' '{print $1}' | \
        awk -F',' '{print $2}'
  register: vnf_instance_ip

- name: Show the IP
  ansible.builtin.debug:
    var: vnf_instance_ip

- when: vnf_instance_ip.stdout | length == 0
  fail:
    msg: "bad vnf_instance_ip"

- name: Verfiy the number of instances before scaling
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} server list --long | grep -i 'metering.server_group' | wc -l
  register: instance_count1

- shell: |
    cat {{ ansible_env.HOME }}/.ssh/known_hosts | grep "{{ item | trim }}"
  with_items: "{{ vnf_instance_ip.stdout_lines }}"
  ignore_errors: true

- name: Remove the existing hostkey, if there is one for the target IP
  ansible.builtin.lineinfile:
    dest: '{{ ansible_env.HOME }}/.ssh/known_hosts'
    state: absent
    regexp: "{{ item |trim }}"
  with_items: "{{ vnf_instance_ip.stdout_lines }}"

- shell: |
    cat {{ ansible_env.HOME }}/.ssh/known_hosts | grep "{{ item | trim }}"
  with_items: "{{ vnf_instance_ip.stdout_lines }}"
  ignore_errors: true

  # NOTE: Disabling strict host key checking so that ssh doesn't give an error
  # when the host key changes i.e. if a new VM has been assigned a
  # previously-used IP address, which will happen during local testing but not
  # in CI
  # NOTE: the with_items is because I was capturing both IPs initially, and
  # using both in case the order was not consistent.
  # Disabling hostkey checking didn't work. I need to remove the key from the known_hosts file before trying to tun this.
  # The key removal should move to some pre/pre-run stage.
- name: Test automatic scaling up of instances
  ansible.builtin.shell: |
    sshpass -p gocubsgo ssh -o StrictHostKeyChecking=False cirros@{{ item | trim }} "sudo yes > /dev/null &"
  register: busy_process
  with_items: "{{ vnf_instance_ip.stdout_lines }}"

- name: Verify that the alarm has been triggered
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} alarm list -c state -c name -f value| \
        grep -i "cpu_alarm_high" | \
        awk '{print $2}'
  retries: 100
  delay: 5
  register: result
  until: result.stdout == "alarm"

- name: Verify that the Orchestration service has scaled up the instances
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} server list --long|grep -i metering.server_group | wc -l
  retries: 100
  delay: 5
  register: instance_count2
  until: instance_count2.stdout == "3"

- name: Stop the busy process
  ansible.builtin.shell: |
    sshpass -p gocubsgo ssh cirros@{{ item | trim }} "sudo killall yes"
  register: kill_busy_process
  with_items: "{{ vnf_instance_ip.stdout_lines }}"

- name: Test automatic scaling down of instances
  ansible.builtin.pause:
    minutes: 5

- name: Verify that the alarm has been triggered
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} alarm list -c state -c name -f value| \
        grep -i "cpu_alarm_low" | \
        awk '{print $2}'
  retries: 100
  delay: 5
  register: result
  until: result.stdout == "alarm"

  # TODO: the metering.server group metadata was used for gnocchi alarm
  # selection.
  # prom uses the instance name, so the metadata MIGHT be removed, and a new
  # check for whether the scaling group has scaled down may be needed.
- name: Verify that the Orchestration service has scaled down the instances
  ansible.builtin.shell: |
    # source ~/overcloudrc;
    {{ openstack_cmd }} server list --long|grep -i metering.server_group |wc -l
  retries: 100
  delay: 5
  register: instance_count3
  until: instance_count3.stdout == "1"